{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hlLb19CQj4tXmvnX94U3esQivmHvcSzG",
      "authorship_tag": "ABX9TyPztrUE/OGGS+6o06wuNPUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/An0816/PyTorchZeroToAll/blob/main/lec7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLemWuwTEoLR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJs4o3UYEy6-"
      },
      "source": [
        "- Matrix Multiplication   \n",
        "`linear = torch.nn.Linear(2, 1)` : two input and one output  \n",
        "\n",
        "-> We can make it **wide** and **deep**\n",
        "```py\n",
        "l1 = torch.nn.Linear(2, 4)\n",
        "l2 = torch.nn.Linear(4, 3)\n",
        "l3 = torch.nn.Linear(3, 1)\n",
        "```\n",
        "-> l1의 2랑 l3의 1은 fixed(위에서 two input and one output으로 정의했기 때문)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_I5rDWOCaE",
        "outputId": "3d2ede80-1bad-4be3-ddfc-1cd9585faf01"
      },
      "source": [
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "xy = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/Deep_Learning_Lecture/diabetes.csv', delimiter = ',', dtype = np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "\n",
        "# step1. design your model using class\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6) # 8 inputs\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1) # 1 output\n",
        "        # l1의 8과 l3의 1은 fixed\n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.BCELoss(size_average = True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "# step2. construct loss and optimizer\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(f\"epoch : {epoch}\\tloss.data:{loss.data}\\n\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0\tloss.data:0.8156114816665649\n",
            "\n",
            "epoch : 1\tloss.data:0.7989674806594849\n",
            "\n",
            "epoch : 2\tloss.data:0.7839242815971375\n",
            "\n",
            "epoch : 3\tloss.data:0.7703381180763245\n",
            "\n",
            "epoch : 4\tloss.data:0.7580755949020386\n",
            "\n",
            "epoch : 5\tloss.data:0.7470133900642395\n",
            "\n",
            "epoch : 6\tloss.data:0.7370380163192749\n",
            "\n",
            "epoch : 7\tloss.data:0.7280453443527222\n",
            "\n",
            "epoch : 8\tloss.data:0.7199406027793884\n",
            "\n",
            "epoch : 9\tloss.data:0.7126368880271912\n",
            "\n",
            "epoch : 10\tloss.data:0.7060559988021851\n",
            "\n",
            "epoch : 11\tloss.data:0.7001262903213501\n",
            "\n",
            "epoch : 12\tloss.data:0.6947832107543945\n",
            "\n",
            "epoch : 13\tloss.data:0.6899685859680176\n",
            "\n",
            "epoch : 14\tloss.data:0.6856295466423035\n",
            "\n",
            "epoch : 15\tloss.data:0.681718647480011\n",
            "\n",
            "epoch : 16\tloss.data:0.678193211555481\n",
            "\n",
            "epoch : 17\tloss.data:0.6750146746635437\n",
            "\n",
            "epoch : 18\tloss.data:0.6721482872962952\n",
            "\n",
            "epoch : 19\tloss.data:0.6695628762245178\n",
            "\n",
            "epoch : 20\tloss.data:0.6672306060791016\n",
            "\n",
            "epoch : 21\tloss.data:0.6651259660720825\n",
            "\n",
            "epoch : 22\tloss.data:0.6632264256477356\n",
            "\n",
            "epoch : 23\tloss.data:0.6615116000175476\n",
            "\n",
            "epoch : 24\tloss.data:0.6599631905555725\n",
            "\n",
            "epoch : 25\tloss.data:0.6585647463798523\n",
            "\n",
            "epoch : 26\tloss.data:0.6573013663291931\n",
            "\n",
            "epoch : 27\tloss.data:0.6561598777770996\n",
            "\n",
            "epoch : 28\tloss.data:0.6551280617713928\n",
            "\n",
            "epoch : 29\tloss.data:0.6541954278945923\n",
            "\n",
            "epoch : 30\tloss.data:0.6533521413803101\n",
            "\n",
            "epoch : 31\tloss.data:0.6525894999504089\n",
            "\n",
            "epoch : 32\tloss.data:0.6518996357917786\n",
            "\n",
            "epoch : 33\tloss.data:0.6512754559516907\n",
            "\n",
            "epoch : 34\tloss.data:0.6507106423377991\n",
            "\n",
            "epoch : 35\tloss.data:0.6501994132995605\n",
            "\n",
            "epoch : 36\tloss.data:0.6497365832328796\n",
            "\n",
            "epoch : 37\tloss.data:0.6493175625801086\n",
            "\n",
            "epoch : 38\tloss.data:0.6489380598068237\n",
            "\n",
            "epoch : 39\tloss.data:0.648594319820404\n",
            "\n",
            "epoch : 40\tloss.data:0.6482828855514526\n",
            "\n",
            "epoch : 41\tloss.data:0.6480007767677307\n",
            "\n",
            "epoch : 42\tloss.data:0.6477451324462891\n",
            "\n",
            "epoch : 43\tloss.data:0.6475133895874023\n",
            "\n",
            "epoch : 44\tloss.data:0.6473033428192139\n",
            "\n",
            "epoch : 45\tloss.data:0.6471129059791565\n",
            "\n",
            "epoch : 46\tloss.data:0.6469401121139526\n",
            "\n",
            "epoch : 47\tloss.data:0.6467835903167725\n",
            "\n",
            "epoch : 48\tloss.data:0.6466414928436279\n",
            "\n",
            "epoch : 49\tloss.data:0.6465126276016235\n",
            "\n",
            "epoch : 50\tloss.data:0.646395742893219\n",
            "\n",
            "epoch : 51\tloss.data:0.6462897062301636\n",
            "\n",
            "epoch : 52\tloss.data:0.6461933851242065\n",
            "\n",
            "epoch : 53\tloss.data:0.6461060047149658\n",
            "\n",
            "epoch : 54\tloss.data:0.6460266709327698\n",
            "\n",
            "epoch : 55\tloss.data:0.6459546685218811\n",
            "\n",
            "epoch : 56\tloss.data:0.6458892822265625\n",
            "\n",
            "epoch : 57\tloss.data:0.645829975605011\n",
            "\n",
            "epoch : 58\tloss.data:0.6457760334014893\n",
            "\n",
            "epoch : 59\tloss.data:0.6457270383834839\n",
            "\n",
            "epoch : 60\tloss.data:0.6456825137138367\n",
            "\n",
            "epoch : 61\tloss.data:0.645642101764679\n",
            "\n",
            "epoch : 62\tloss.data:0.6456053853034973\n",
            "\n",
            "epoch : 63\tloss.data:0.6455719470977783\n",
            "\n",
            "epoch : 64\tloss.data:0.6455416083335876\n",
            "\n",
            "epoch : 65\tloss.data:0.6455140113830566\n",
            "\n",
            "epoch : 66\tloss.data:0.645488977432251\n",
            "\n",
            "epoch : 67\tloss.data:0.6454660892486572\n",
            "\n",
            "epoch : 68\tloss.data:0.6454454064369202\n",
            "\n",
            "epoch : 69\tloss.data:0.6454264521598816\n",
            "\n",
            "epoch : 70\tloss.data:0.6454092264175415\n",
            "\n",
            "epoch : 71\tloss.data:0.6453936100006104\n",
            "\n",
            "epoch : 72\tloss.data:0.645379364490509\n",
            "\n",
            "epoch : 73\tloss.data:0.6453663110733032\n",
            "\n",
            "epoch : 74\tloss.data:0.6453545689582825\n",
            "\n",
            "epoch : 75\tloss.data:0.6453436613082886\n",
            "\n",
            "epoch : 76\tloss.data:0.6453338861465454\n",
            "\n",
            "epoch : 77\tloss.data:0.6453248858451843\n",
            "\n",
            "epoch : 78\tloss.data:0.6453167200088501\n",
            "\n",
            "epoch : 79\tloss.data:0.6453092694282532\n",
            "\n",
            "epoch : 80\tloss.data:0.6453025341033936\n",
            "\n",
            "epoch : 81\tloss.data:0.6452962160110474\n",
            "\n",
            "epoch : 82\tloss.data:0.6452905535697937\n",
            "\n",
            "epoch : 83\tloss.data:0.6452853679656982\n",
            "\n",
            "epoch : 84\tloss.data:0.6452805995941162\n",
            "\n",
            "epoch : 85\tloss.data:0.6452761888504028\n",
            "\n",
            "epoch : 86\tloss.data:0.6452721953392029\n",
            "\n",
            "epoch : 87\tloss.data:0.6452685594558716\n",
            "\n",
            "epoch : 88\tloss.data:0.6452651023864746\n",
            "\n",
            "epoch : 89\tloss.data:0.6452620029449463\n",
            "\n",
            "epoch : 90\tloss.data:0.6452591419219971\n",
            "\n",
            "epoch : 91\tloss.data:0.645256519317627\n",
            "\n",
            "epoch : 92\tloss.data:0.6452540755271912\n",
            "\n",
            "epoch : 93\tloss.data:0.6452518701553345\n",
            "\n",
            "epoch : 94\tloss.data:0.6452497839927673\n",
            "\n",
            "epoch : 95\tloss.data:0.6452478766441345\n",
            "\n",
            "epoch : 96\tloss.data:0.6452460885047913\n",
            "\n",
            "epoch : 97\tloss.data:0.6452444791793823\n",
            "\n",
            "epoch : 98\tloss.data:0.6452428698539734\n",
            "\n",
            "epoch : 99\tloss.data:0.6452414393424988\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar6jspT_PQMP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}